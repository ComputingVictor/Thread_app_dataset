{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Multiclass sentiment analysis of the users\n    \n<strong>Thread app dataset: 37000 entities</strong>\n    \n\n\n\n<p style=\"text-align:right\">V&iacute;ctor Viloria  (<em>ComputingVictor</em>)</p>\n\n","metadata":{}},{"cell_type":"markdown","source":"<hr style=\"border:1px solid gray\">","metadata":{}},{"cell_type":"markdown","source":"# Structure","metadata":{}},{"cell_type":"markdown","source":"[Introduction](#introduccion) \n\n[1. Python libraries](#librerias) \n\n[2. Data Loading](#lectura) \n\n[3. Exploratory Data Analysis ](#EDA) \n\n   - 3.1 Shape and types\n   - 3.2 Nulls\n   - 3.3 Numerical Analysis\n   - 3.4 Temporal Series Analysis\n   \n[4. Text transformation](#text) \n\n\n   - 4.1 Tokenizer\n   - 4.2 Vectorization (TF-IDF)\n   \n[5. ML Models](#ml) \n\n   - 5.1 Linear Regression\n   - 5.2 SVC\n   - 5.3 LightGBM\n\n[6. Conclusions](#conclusions) ","metadata":{}},{"cell_type":"markdown","source":"<hr style=\"border:1px solid gray\">","metadata":{}},{"cell_type":"markdown","source":"# Introduction ","metadata":{}},{"cell_type":"markdown","source":"In this notebook, We will use the *Thread app dataset: 37000 entities*, we will proceed with data preprocessing for natural language processing (NLP) on reviews posted on the Threads app. Then we will train different models, MLand Neuronal networks to predict the sentiment of each review.","metadata":{}},{"cell_type":"markdown","source":"# 1. Python libraries","metadata":{}},{"cell_type":"code","source":"# Import pandas.\n\nimport pandas as pd\nimport numpy as np\n\n# Import nltk.\n\nimport nltk\nnltk.download('punkt')\n\n# Import nltk stopwords.\n\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\n# Import wordcloud and matplotlib.\n\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Vectorizer.\n\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# ML models.\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\nimport lightgbm as lgb\nfrom sklearn.preprocessing import LabelEncoder\n\n# Scores.\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import fbeta_score\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:30:28.875520Z","iopub.execute_input":"2023-08-21T15:30:28.875937Z","iopub.status.idle":"2023-08-21T15:30:28.884653Z","shell.execute_reply.started":"2023-08-21T15:30:28.875906Z","shell.execute_reply":"2023-08-21T15:30:28.883553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data Loading \n","metadata":{}},{"cell_type":"code","source":"# Load the csv file.\n\nthreads_df = pd.read_csv(\"/kaggle/input/37000-reviews-of-thread-app-dataset/37000_reviews_of_thread_app.csv\",index_col=[0])\n\n# Display the first rows.\n\nthreads_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:25:04.732066Z","iopub.execute_input":"2023-08-21T15:25:04.732628Z","iopub.status.idle":"2023-08-21T15:25:05.018961Z","shell.execute_reply.started":"2023-08-21T15:25:04.732575Z","shell.execute_reply":"2023-08-21T15:25:05.017891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  3. Exploratory data analysis ","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Shape and types","metadata":{}},{"cell_type":"code","source":"# Print the shape of the dataframe.\n\nprint(\"The dataframe has {} rows and {} columns.\".format(threads_df.shape[0], threads_df.shape[1]))\n\nprint(\"---------------------------------------------------------------------------------------\")\n\n# Print the column names and datatypes.\n\nthreads_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:25:05.020994Z","iopub.execute_input":"2023-08-21T15:25:05.021346Z","iopub.status.idle":"2023-08-21T15:25:05.087506Z","shell.execute_reply.started":"2023-08-21T15:25:05.021315Z","shell.execute_reply":"2023-08-21T15:25:05.086232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2 Nulls","metadata":{}},{"cell_type":"code","source":"# Print the number of null values in each column.\n\nthreads_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:25:05.089359Z","iopub.execute_input":"2023-08-21T15:25:05.089837Z","iopub.status.idle":"2023-08-21T15:25:05.150667Z","shell.execute_reply.started":"2023-08-21T15:25:05.089795Z","shell.execute_reply":"2023-08-21T15:25:05.149350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We notice that there are some rows with high number of null data that are irrelevant for our analysis, we proceed to drop them. For `thumbs_up` we will convert the nulls to 0.","metadata":{}},{"cell_type":"code","source":"# Drop the developer columns, appVersion and review_title variable.\n\nthreads_df = threads_df.drop(['review_title', 'developer_response', 'developer_response_date', 'appVersion'], axis=1)\n\n# Convert nulls of thumbs_up to 0.\n\nthreads_df['thumbs_up'] = threads_df['thumbs_up'].fillna(0)\n\n# Display the first rows of \"threads_df\".\n\nthreads_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:25:05.153538Z","iopub.execute_input":"2023-08-21T15:25:05.153880Z","iopub.status.idle":"2023-08-21T15:25:05.175072Z","shell.execute_reply.started":"2023-08-21T15:25:05.153852Z","shell.execute_reply":"2023-08-21T15:25:05.173979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the number of null values in each column.\n\nthreads_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:25:05.176655Z","iopub.execute_input":"2023-08-21T15:25:05.176990Z","iopub.status.idle":"2023-08-21T15:25:05.227303Z","shell.execute_reply.started":"2023-08-21T15:25:05.176961Z","shell.execute_reply":"2023-08-21T15:25:05.226000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.3 Numerical Analysis","metadata":{}},{"cell_type":"markdown","source":"#### 3.3.1. Unique Values","metadata":{}},{"cell_type":"markdown","source":"First of all, we will check the unique values for the most important variables","metadata":{}},{"cell_type":"code","source":"# Check unique values\nunique_sources = threads_df['source'].unique()\nunique_ratings = threads_df['rating'].unique()\nunique_languages = threads_df['laguage_code'].unique()\nunique_countries = threads_df['country_code'].unique()\nunique_thumbs_up = threads_df['thumbs_up'].unique()\n\nprint(\"Unique values for source:\", unique_sources)\nprint(\"Unique values for rating:\", unique_ratings)\nprint(\"Unique values for language_code:\", unique_languages)\nprint(\"Unique values for country_code:\", unique_countries)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:25:05.228772Z","iopub.execute_input":"2023-08-21T15:25:05.229199Z","iopub.status.idle":"2023-08-21T15:25:05.246031Z","shell.execute_reply.started":"2023-08-21T15:25:05.229157Z","shell.execute_reply":"2023-08-21T15:25:05.244913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We found multiple variables in `ratings` and `source`. Let's check the number of reviews by rating.","metadata":{}},{"cell_type":"markdown","source":"#### 3.3.2. Number of Reviews by rating","metadata":{}},{"cell_type":"code","source":"# Group by 'rating' and count reviews.\nratings_count = threads_df['rating'].value_counts().sort_index()\n\n# Plot.\nratings_count.plot(kind='bar', color='skyblue')\nplt.xlabel('Rating')\nplt.ylabel('Number of Reviews')\nplt.title('Number of Reviews by Rating')\nplt.xticks(rotation=0)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:25:05.247700Z","iopub.execute_input":"2023-08-21T15:25:05.248331Z","iopub.status.idle":"2023-08-21T15:25:05.567932Z","shell.execute_reply.started":"2023-08-21T15:25:05.248292Z","shell.execute_reply":"2023-08-21T15:25:05.566721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, the ratings are polarized. With the 1 and 5 ratings with +10k values, while the other rating values have less data.","metadata":{}},{"cell_type":"markdown","source":"#### 3.3.3. Top 5 of total thumbs in the dataset","metadata":{}},{"cell_type":"code","source":"# Group by 'source' and count reviews.\nthumbs_count = threads_df['thumbs_up'].value_counts().sort_values(ascending=False)\n\nthumbs_count.head(5).plot(kind='bar')\nplt.xlabel('Rating')\nplt.ylabel('Number of Reviews')\nplt.title('Number of Reviews by Store')\nplt.xticks(rotation=0)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:25:05.569526Z","iopub.execute_input":"2023-08-21T15:25:05.569957Z","iopub.status.idle":"2023-08-21T15:25:05.871493Z","shell.execute_reply.started":"2023-08-21T15:25:05.569925Z","shell.execute_reply":"2023-08-21T15:25:05.870304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3.3.4. Number of Reviews by Store","metadata":{}},{"cell_type":"code","source":"# Group by 'source' and count reviews.\nratings_count = threads_df['source'].value_counts().sort_index()\n\n# Plot.\nratings_count.plot(kind='bar')\nplt.xlabel('Rating')\nplt.ylabel('Number of Reviews')\nplt.title('Number of Reviews by Store')\nplt.xticks(rotation=0)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:25:05.872853Z","iopub.execute_input":"2023-08-21T15:25:05.873191Z","iopub.status.idle":"2023-08-21T15:25:06.191365Z","shell.execute_reply.started":"2023-08-21T15:25:05.873162Z","shell.execute_reply":"2023-08-21T15:25:06.190548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most of the reviews come from Google Play.","metadata":{}},{"cell_type":"markdown","source":"#### 3.3.5. Users with most reviews.","metadata":{}},{"cell_type":"code","source":"# Group by 'source' and count reviews.\nuser_count = threads_df['user_name'].value_counts().sort_values(ascending=False)\n\nuser_count.head(5).plot(kind='bar')\nplt.xlabel('Rating')\nplt.ylabel('Number of Reviews')\nplt.title('Number of Reviews by User')\nplt.xticks(rotation=0)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:25:06.195009Z","iopub.execute_input":"2023-08-21T15:25:06.195351Z","iopub.status.idle":"2023-08-21T15:25:06.515170Z","shell.execute_reply.started":"2023-08-21T15:25:06.195321Z","shell.execute_reply":"2023-08-21T15:25:06.514359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see there are several people with same names or repeated accounts that reviewed more than once.","metadata":{}},{"cell_type":"markdown","source":"### 3.4 Temporal Series Analysis","metadata":{}},{"cell_type":"code","source":"# Convert 'review_date' to datetime and extract only the date part.\n\nthreads_df['review_date'] = pd.to_datetime(threads_df['review_date']).dt.date\n\n# Group by 'review_date' (only the date) and count reviews.\n\ndaily_reviews = threads_df.groupby('review_date').size()\n\n\n# Plot.\n\ndaily_reviews.plot(kind='line', marker='o')\nplt.xlabel('Date')\nplt.ylabel('Number of Reviews')\nplt.title('Total Reviews per Date')\nplt.tight_layout()\nplt.grid(True)\nplt.xticks(rotation=45) \nplt.subplots_adjust(bottom=0.25)  \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:25:06.516457Z","iopub.execute_input":"2023-08-21T15:25:06.517124Z","iopub.status.idle":"2023-08-21T15:25:06.944218Z","shell.execute_reply.started":"2023-08-21T15:25:06.517082Z","shell.execute_reply":"2023-08-21T15:25:06.943100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the temporal Series plot, we can check that most of the reviews came during the first days of the app release. 7 days after, the numbers of reviews dropped considerably, with August at a low","metadata":{}},{"cell_type":"markdown","source":"# 4. Text transfomation ","metadata":{}},{"cell_type":"markdown","source":"### 4.1. Tokenizer","metadata":{}},{"cell_type":"markdown","source":"We will make some transformations in the text with the objective to standardize it. We will convert all to lowercase, then we will remove the sign punctuations, remove the line breaks in case there would be and emoticons.","metadata":{}},{"cell_type":"code","source":"# Convert the text column to lowercase.\n\nthreads_df['review_description'] = threads_df['review_description'].str.lower()\n\n# Delete emoticons with text.\n\nthreads_df['review_description'] = threads_df['review_description'].str.replace('[\\:\\;\\=][\\-\\^]?[\\(\\)\\[\\]\\{\\}\\@D\\|Pp\\$\\*\\+\\#]','')\n\n# Delete punctuation signs.\n\nthreads_df['review_description'] = threads_df['review_description'].str.replace('[^\\w\\s]','')\n\n# Delete /n from text.\n\nthreads_df['review_description'] = threads_df['review_description'].str.replace('\\n',' ')","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:25:06.945414Z","iopub.execute_input":"2023-08-21T15:25:06.945744Z","iopub.status.idle":"2023-08-21T15:25:07.175876Z","shell.execute_reply.started":"2023-08-21T15:25:06.945714Z","shell.execute_reply":"2023-08-21T15:25:07.174577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Once the transformation is done, we proceed to tokenize the text and delete the stopwords. Just to have the text ready to apply it into differents models. ","metadata":{}},{"cell_type":"code","source":"# Convert the reviewText column to string.\n\nthreads_df['review_description'] = threads_df['review_description'].astype(str)\n\n# Tokenize the text.\n\nthreads_df['review_description'] = threads_df['review_description'].apply(nltk.word_tokenize)\n\n# Delete the stopwords from text.\n\nstop_words = set(stopwords.words('english'))\n\nthreads_df['review_description'] = threads_df['review_description'].apply(lambda x: [item for item in x if item not in stop_words])\n\n# Convert reviewText column to string with space between words.\n\nthreads_df['review_description'] = threads_df['review_description'].apply(lambda x: ' '.join(x))\n\n# Display first 5 rows\n\nthreads_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:25:07.177340Z","iopub.execute_input":"2023-08-21T15:25:07.177672Z","iopub.status.idle":"2023-08-21T15:25:11.937286Z","shell.execute_reply.started":"2023-08-21T15:25:07.177643Z","shell.execute_reply":"2023-08-21T15:25:11.936169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check the wordclouds.","metadata":{}},{"cell_type":"code","source":"# Create a wordcloud of the first 100 reviews.\n\nwordcloud = WordCloud().generate(str(threads_df['review_description']))\n\nplt.imshow(wordcloud, interpolation='bilinear')\n\nplt.axis(\"off\")\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:25:11.938759Z","iopub.execute_input":"2023-08-21T15:25:11.939464Z","iopub.status.idle":"2023-08-21T15:25:12.239283Z","shell.execute_reply.started":"2023-08-21T15:25:11.939430Z","shell.execute_reply":"2023-08-21T15:25:12.237991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The most common words are related with his competitor \"Twitter\" and different opinions appeared in order to the most common ratins we checked before: 1 and 5. Lets see the most used words:","metadata":{}},{"cell_type":"code","source":"# Histogram of the top 10 most common words.\n\ntop_10_words = Counter(\" \".join(threads_df['review_description']).split()).most_common(10)\n\ntop_10_df = pd.DataFrame(top_10_words)\n\ntop_10_df.columns=[\"Word\", \"Frequency\"]\n\nsns.barplot(x=\"Word\", y=\"Frequency\", data=top_10_df)\n\nplt.title(\"Top 10 most common words\")\n\nplt.xlabel(\"Word\")\n\nplt.ylabel(\"Frequency\")\n\nplt.xticks(rotation=45)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:25:12.240955Z","iopub.execute_input":"2023-08-21T15:25:12.241544Z","iopub.status.idle":"2023-08-21T15:25:12.590068Z","shell.execute_reply.started":"2023-08-21T15:25:12.241497Z","shell.execute_reply":"2023-08-21T15:25:12.588790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally we will drop variables that won't be relevant for the training of the models.","metadata":{}},{"cell_type":"code","source":"# Drop irrelevant variables\n\nthreads_df = threads_df.drop(['user_name','laguage_code', 'country_code', 'review_id', 'source','review_date','thumbs_up'], axis=1)\n\n# Display the first rows.\n\nthreads_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:25:12.591674Z","iopub.execute_input":"2023-08-21T15:25:12.592146Z","iopub.status.idle":"2023-08-21T15:25:12.607523Z","shell.execute_reply.started":"2023-08-21T15:25:12.592100Z","shell.execute_reply":"2023-08-21T15:25:12.606067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.2. Vectorization (TF-IDF)","metadata":{}},{"cell_type":"code","source":"# Load the vectorizer\n\ntfidf_vectorizer = TfidfVectorizer(max_df=0.99,min_df=0.01)\n\n# Transform the tokens.\n\ntfidf_matrix = tfidf_vectorizer.fit_transform(threads_df['review_description'])","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:25:12.609549Z","iopub.execute_input":"2023-08-21T15:25:12.610023Z","iopub.status.idle":"2023-08-21T15:25:12.981758Z","shell.execute_reply.started":"2023-08-21T15:25:12.609979Z","shell.execute_reply":"2023-08-21T15:25:12.980188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. ML Models","metadata":{}},{"cell_type":"markdown","source":"Once vectorized the text, we proceed with the split into train and test sets. In our case we will try multiclass ML models.","metadata":{}},{"cell_type":"code","source":"# Split into X and y.\n\nX = tfidf_matrix\ny = threads_df['rating']\n\n# Split into train and test\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=12345, stratify=y)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:25:12.983303Z","iopub.execute_input":"2023-08-21T15:25:12.983822Z","iopub.status.idle":"2023-08-21T15:25:13.012871Z","shell.execute_reply.started":"2023-08-21T15:25:12.983772Z","shell.execute_reply":"2023-08-21T15:25:13.011431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.1. Linear Regression","metadata":{}},{"cell_type":"code","source":"# Load the Linear Regression Classifier.\n\nclf = LogisticRegression()\n\n# Train the model.\n\nclf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:25:13.014299Z","iopub.execute_input":"2023-08-21T15:25:13.015251Z","iopub.status.idle":"2023-08-21T15:25:13.668192Z","shell.execute_reply.started":"2023-08-21T15:25:13.015201Z","shell.execute_reply":"2023-08-21T15:25:13.667053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the X_test.\n\ny_pred = clf.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\n\n\n# Evaluation.\n\nprint(classification_report(y_test,y_pred))\n\n# Print: the accuracy score.\n\nprint(\"Accuracy:\",accuracy_score(y_test, y_pred))\n\n# Print: F-2.\n\nprint(\"F2 micro:\",fbeta_score(y_test, y_pred, beta=2, average='micro'))\n\n# Print: F-2.\n\nprint(\"F2 macro:\",fbeta_score(y_test, y_pred, beta=2, average='macro'))","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:25:13.669905Z","iopub.execute_input":"2023-08-21T15:25:13.670620Z","iopub.status.idle":"2023-08-21T15:25:13.713279Z","shell.execute_reply.started":"2023-08-21T15:25:13.670576Z","shell.execute_reply":"2023-08-21T15:25:13.712048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.2. LinearSVC","metadata":{}},{"cell_type":"code","source":"# Load SVC and train the model.\n\nclf = LinearSVC()\nclf.fit(X_train, y_train)\n\n# Predict the X_test.\n\ny_pred = clf.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:25:13.715096Z","iopub.execute_input":"2023-08-21T15:25:13.715650Z","iopub.status.idle":"2023-08-21T15:25:14.410180Z","shell.execute_reply.started":"2023-08-21T15:25:13.715603Z","shell.execute_reply":"2023-08-21T15:25:14.409241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation.\n\nprint(classification_report(y_test,y_pred))\n\n# Print: the accuracy score.\n\nprint(\"Accuracy:\",accuracy_score(y_test, y_pred))\n\n# Print: F-2.\n\nprint(\"F2 micro:\",fbeta_score(y_test, y_pred, beta=2, average='micro'))\n\n# Print: F-2.\n\nprint(\"F2 macro:\",fbeta_score(y_test, y_pred, beta=2, average='macro'))","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:25:14.411551Z","iopub.execute_input":"2023-08-21T15:25:14.411895Z","iopub.status.idle":"2023-08-21T15:25:14.450276Z","shell.execute_reply.started":"2023-08-21T15:25:14.411866Z","shell.execute_reply":"2023-08-21T15:25:14.449086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.3. LightGBM","metadata":{}},{"cell_type":"code","source":"# Due to the format of the target we will use Label Encoder.\n\nle = LabelEncoder()\ny = le.fit_transform(threads_df['rating'])\n\n# Luego, divide tus datos en conjuntos de entrenamiento y prueba nuevamente\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:30:36.782713Z","iopub.execute_input":"2023-08-21T15:30:36.783087Z","iopub.status.idle":"2023-08-21T15:30:36.806503Z","shell.execute_reply.started":"2023-08-21T15:30:36.783058Z","shell.execute_reply":"2023-08-21T15:30:36.805553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LightGBM format.\n\nd_train = lgb.Dataset(X_train, label=y_train)\n\n# Parámetros para LightGBM, puedes ajustar estos según tus necesidades\nparams = {\n    'objective': 'multiclass',\n    'num_class': len(np.unique(y)),\n    'metric': 'multi_logloss',\n    'boosting_type': 'gbdt',\n    'num_leaves': 31,\n    'learning_rate': 0.05,\n    'feature_fraction': 0.9\n}\n\n# Entrenar el modelo\nclf = lgb.train(params, d_train,)\n\n# Realizar predicciones\ny_pred = clf.predict(X_test, num_iteration=clf.best_iteration)\n\n# Después de obtener y_pred de LightGBM:\ny_pred_class = np.argmax(y_pred, axis=1)\n\n# Evaluar el modelo\naccuracy = accuracy_score(y_test, y_pred_class)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:30:39.399811Z","iopub.execute_input":"2023-08-21T15:30:39.400220Z","iopub.status.idle":"2023-08-21T15:30:48.030180Z","shell.execute_reply.started":"2023-08-21T15:30:39.400188Z","shell.execute_reply":"2023-08-21T15:30:48.028901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation.\n\nprint(classification_report(y_test,y_pred_class))\n\n# Print: the accuracy score.\n\nprint(\"Accuracy:\",accuracy_score(y_test, y_pred_class))\n\n# Print: F-2.\n\nprint(\"F2 micro:\",fbeta_score(y_test, y_pred_class, beta=2, average='micro'))\n\n# Print: F-2.\n\nprint(\"F2 macro:\",fbeta_score(y_test, y_pred_class, beta=2, average='macro'))","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:31:21.024975Z","iopub.execute_input":"2023-08-21T15:31:21.025394Z","iopub.status.idle":"2023-08-21T15:31:21.068961Z","shell.execute_reply.started":"2023-08-21T15:31:21.025362Z","shell.execute_reply":"2023-08-21T15:31:21.067572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Conclusions ","metadata":{}},{"cell_type":"markdown","source":"After several trials with differente models, the accuracy is okay (60-61%) , by the way the macro f2 and f1 scores are poor, due to the imbalance of the dataset in ratings like 2,3 and 4 compared with 1 and 5.","metadata":{}}]}